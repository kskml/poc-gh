import os
from openai import OpenAI

# ==========================================
# 1. YOUR INPUTS (Paste your data here)
# ==========================================

# The git diff string
CODE_DIFF = """
diff --git a/src/api.py b/src/api.py
@@ -12,7 +12,7 @@ class ApiClient:
-    def __init__(self, host, port):
+    def __init__(self, host, port, enable_logging=False):
         self.host = host
         self.port = port
+        self.logger = setup_logging() if enable_logging else None
"""

# The current content of the file
ORIGINAL_CONTENT = """
= API Client Configuration

== Initialization

To initialize the client, provide the `host` and `port`.

[source, python]
----
client = ApiClient(host="localhost", port=8080)
----

=== Parameters

`host`:: The server hostname.
`port`:: The server port number.
"""

# The proposed change description
PROPOSED_CHANGE = """
The __init__ method now supports an optional `enable_logging` parameter. 
Update the initialization example and the parameters list to reflect this new boolean argument.
"""

# ==========================================
# 2. LOGIC & LLM INTEGRATION
# ==========================================

def generate_updated_content(client, diff, original, change):
    """
    Sends the context to the LLM to generate the updated AsciiDoc file.
    """
    
    system_prompt = """
You are an expert technical writer maintaining an AsciiDoc repository. 
Your goal is to update a documentation file based on specific code changes.

RULES:
1. Output ONLY the raw content of the updated AsciiDoc file. Do not use markdown code blocks.
2. Preserve the existing structure and style of the original document.
3. Implement the changes described in the 'Proposed Change' section.
4. **CRITICAL**: For every line you modify or add, you must insert a comment on the line immediately before it.
   - Format: // LLM-UPDATE: <Reason for change>
   - Example:
     // LLM-UPDATE: Added new parameter 'timeout'.
     `timeout`:: The timeout in seconds.
"""

    user_prompt = f"""
### Original AsciiDoc Content:
{original}

### Code Diff:
{diff}

### Proposed Change:
{change}

Please generate the updated AsciiDoc file now.
"""

    print("Sending request to LLM...")
    
    response = client.chat.completions.create(
        model="gpt-4o", # Recommended for high-quality code/doc correlation
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        temperature=0.1 
    )

    return response.choices[0].message.content

# ==========================================
# 3. MAIN EXECUTION
# ==========================================

if __name__ == "__main__":
    # Initialize client. 
    # Make sure OPENAI_API_KEY is set in your environment variables.
    # Mac/Linux: export OPENAI_API_KEY='sk-...'
    # Windows: set OPENAI_API_KEY=sk-...
    
    api_key = os.environ.get("OPENAI_API_KEY")
    if not api_key:
        print("ERROR: Please set the OPENAI_API_KEY environment variable.")
        exit(1)

    client = OpenAI(api_key=api_key)

    try:
        # Generate the content
        updated_file_content = generate_updated_content(
            client, 
            CODE_DIFF, 
            ORIGINAL_CONTENT, 
            PROPOSED_CHANGE
        )

        # Define output filename
        output_filename = "updated_docs.adoc"
        
        # Write to file
        with open(output_filename, "w", encoding="utf-8") as f:
            f.write(updated_file_content)

        print(f"\nSuccess! Updated content written to '{output_filename}'.")
        print("You can now use this file content for your Pull Request.")
        
        # Optional: Print preview
        print("\n--- PREVIEW ---")
        print(updated_file_content)

    except Exception as e:
        print(f"An error occurred: {e}")
