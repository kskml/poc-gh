def analyze_single_section(client, deployment_name, section_header, section_content, full_diff, local_diag_path):
    """
    Invokes LLM with Text AND Diagram context.
    UPDATE: Forces LLM to return corrected diagram code if gap is found.
    """
    
    # REFINED REGEX
    pattern = re.compile(r'<<<\s*(PLANTUML|DRAWIO|DRAW)\s*DIAGRAM\s*:\s*(.*?)\s*>>>', re.IGNORECASE)
    
    matches = pattern.findall(section_content)
    
    if len(matches) == 0:
        if "DIAGRAM" in section_content:
            print(f"      ‚ö†Ô∏è  Word 'DIAGRAM' found but regex didn't match.")
            snippet = section_content[:500]
            print(f"      Section Start Snippet: {snippet}...")
        else:
            print(f"      ‚ÑπÔ∏è  No diagrams detected in this section.")

    diagram_contexts = []
    
    for match in matches:
        diag_type, diag_name = match
        diag_name = diag_name.strip(" :")
        if not diag_name:
            diag_name = "Unknown"
        
        if "plantuml" in diag_type.lower():
            diag_content = find_local_diagram(diag_name, local_diag_path)
            if diag_content:
                diagram_contexts.append(f"\n--- DIAGRAM CONTEXT: {diag_name} ---\n{diag_content}\n")
    
    prompt_diagrams = "\n".join(diagram_contexts) if diagram_contexts else "No local diagrams found for this section."
    
    system_prompt = """
    You are an ASPICE SWE.2 Auditor analyzing a Documentation Section against Code Changes.
    
    **Context:**
    1. Confluence Text Content.
    2. (Optional) Local PlantUML Diagrams.
    
    **Instructions:**
    1. Check if Code Diff affects Text OR Diagram Logic.
    2. Return `NO_IMPACT` if aligned.
    3. If gap found, return ONLY a Markdown table row.
    
    **Corrective Action Requirement:**
    - If the gap is related to a **PlantUML Diagram**, you MUST output the **FULL CORRECTED PLANTUML CODE** inside the Corrective Action column.
    - Provide the corrected code block directly in the cell. Do not place it outside the table.
    
    **Row Format:**
    | ID | Severity | Confluence Section | Impact Scope | SWE.2 Observation | Corrective Action |
    | 1 | üî¥ **NON-CONFORMANT** | <SECTION_TITLE> | UI/Logic/Data/API | [Observation] | [Correction + Corrected Code if applicable] |
    """

    user_prompt = f"""
    <SECTION_TITLE>{section_header}</SECTION_TITLE>
    
    CONFLUENCE TEXT CONTENT:
    {section_content}

    --- 
    
    LOCAL DIAGRAMS (PlantUML Logic):
    {prompt_diagrams}

    ---
    
    GITHUB CODE DIFF:
    {full_diff}
    """
    
    try:
        response = client.chat.completions.create(
            model=deployment_name,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.1
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"Error analyzing section '{section_header}': {e}")
        return "NO_IMPACT"
