import os
import json
from openai import OpenAI

# ==========================================
# 1. YOUR INPUTS (Paste your data here)
# ==========================================

CODE_DIFF = """
diff --git a/src/api.py b/src/api.py
@@ -12,7 +12,7 @@ class ApiClient:
-    def __init__(self, host, port):
+    def __init__(self, host, port, enable_logging=False):
         self.host = host
         self.port = port
+        self.logger = setup_logging() if enable_logging else None
"""

ORIGINAL_CONTENT = """
= API Client Configuration

== Initialization

To initialize the client, provide the `host` and `port`.

[source, python]
----
client = ApiClient(host="localhost", port=8080)
----

=== Parameters

`host`:: The server hostname.
`port`:: The server port number.
"""

PROPOSED_CHANGE = """
The __init__ method now supports an optional `enable_logging` parameter. 
Update the initialization example and the parameters list to reflect this new boolean argument.
"""

# ==========================================
# 2. LOGIC & LLM INTEGRATION
# ==========================================

def generate_update_json(client, diff, original, change):
    """
    Calls LLM and expects a strict JSON response.
    """
    
    # Refined System Prompt for JSON output
    system_prompt = """
You are an automated documentation update assistant. 
You must respond ONLY with a valid JSON object. Do not wrap the output in markdown code blocks.

The JSON object must strictly follow this schema:
{
  "ok": boolean,          // true if updates were applied successfully, false if no changes were needed or error occurred
  "updated_content": string, // the full, updated AsciiDoc file content
  "notes": string,        // a brief summary of changes made or reason for failure
  "change_count": integer // number of distinct sections modified
}

RULES FOR CONTENT GENERATION:
1. In the 'updated_content' string, preserve existing formatting.
2. **CRITICAL**: For every modification, insert an inline comment immediately before the change.
   - Format: // LLM-UPDATE: <Reason for change>
   - Example:
     // LLM-UPDATE: Added parameter 'retries'.
     `retries`:: Number of retry attempts.
"""

    user_prompt = f"""
### Original AsciiDoc Content:
{original}

### Code Diff:
{diff}

### Proposed Change:
{change}

Process the request and return the JSON response.
"""

    print("Sending request to LLM (expecting JSON)...")

    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.1,
            # This forces the model to output valid JSON
            response_format={"type": "json_object"} 
        )

        raw_content = response.choices[0].message.content
        
        # Parse the JSON string into a Python dictionary
        result = json.loads(raw_content)
        return result

    except json.JSONDecodeError:
        return {
            "ok": False,
            "updated_content": original, # Fallback to original
            "notes": "Error: LLM returned invalid JSON.",
            "change_count": 0
        }
    except Exception as e:
        return {
            "ok": False,
            "updated_content": original,
            "notes": f"API Error: {str(e)}",
            "change_count": 0
        }

# ==========================================
# 3. MAIN EXECUTION
# ==========================================

if __name__ == "__main__":
    api_key = os.environ.get("OPENAI_API_KEY")
    if not api_key:
        print("ERROR: Please set the OPENAI_API_KEY environment variable.")
        exit(1)

    client = OpenAI(api_key=api_key)

    # Get the structured response
    result = generate_update_json(client, CODE_DIFF, ORIGINAL_CONTENT, PROPOSED_CHANGE)

    # Pretty print the JSON result to console
    print("\n--- LLM JSON RESPONSE ---")
    print(json.dumps(result, indent=2))

    # Logic for handling the result
    if result.get("ok"):
        print(f"\nNotes from LLM: {result.get('notes')}")
        
        # Save the file
        output_filename = "updated_docs.adoc"
        with open(output_filename, "w", encoding="utf-8") as f:
            f.write(result.get("updated_content", ""))
        
        print(f"Saved updated content to '{output_filename}'.")
    else:
        print("\nUpdate failed or no changes were necessary.")
        print(f"Reason: {result.get('notes')}")
