import os
import logging
import json
from github import Github, GithubException
from openai import AzureOpenAI

# Configure Logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def initialize_clients():
    """Initializes GitHub and Azure OpenAI clients."""
    source_token = os.getenv("SOURCE_GITHUB_TOKEN")
    docs_token = os.getenv("DOCS_GITHUB_TOKEN")
    
    g_source = Github(source_token)
    g_docs = Github(docs_token)
    
    openai_client = AzureOpenAI(
        api_key=os.getenv("AZURE_OPENAI_KEY"),
        api_version="2024-02-01",
        azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT")
    )
    
    deployment_name = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME")
    docs_repo_owner = os.getenv("DOCS_REPO_OWNER")
    docs_repo_name = os.getenv("DOCS_REPO_NAME")
    
    return g_source, g_docs, openai_client, deployment_name, docs_repo_owner, docs_repo_name

def get_pr_diff(g_client, repo_full_name, pr_number):
    """
    Fetches Pull Request details including changed files and the full diff.
    Extracts file status (Added, Modified, Removed, Renamed) to pass to LLM.
    """
    logger.info(f"Fetching PR #{pr_number} from {repo_full_name}")
    repo = g_client.get_repo(repo_full_name)
    pr = repo.get_pull(pr_number)
    
    file_details = []
    full_diff_text = ""
    
    for file in pr.get_files():
        file_info = {
            "filename": file.filename,
            "status": file.status, # added, removed, modified, renamed
            "previous_filename": file.previous_filename
        }
        file_details.append(file_info)
        
        if file.patch:
            full_diff_text += f"File: {file.filename} (Status: {file.status})\nDiff:\n{file.patch}\n\n"
            
    return file_details, full_diff_text, pr.title

def search_candidate_docs(g_docs, docs_repo_full_name, file_path, file_status):
    """
    Searches the Documentation repo for files matching the changed code file path.
    Includes logic to find renamed files if applicable.
    """
    filename_no_ext = os.path.splitext(os.path.basename(file_path))[0]
    candidates = []
    docs_repo = g_docs.get_repo(docs_repo_full_name)
    
    # Heuristic queries
    queries = [
        f"filename:{filename_no_ext} extension:ascii repo:{docs_repo_full_name}",
        f"{filename_no_ext} extension:adoc repo:{docs_repo_full_name}"
    ]
    
    for query in queries:
        try:
            result = docs_repo.search_code(query)
            if result.totalCount > 0:
                candidates.extend([item.path for item in result])
        except Exception as e:
            logger.warning(f"Search API limit or error: {e}")
            
    return list(set(candidates))

def fetch_doc_content(g_docs, docs_repo_full_name, doc_path):
    """Fetches the raw decoded content of a documentation file."""
    try:
        docs_repo = g_docs.get_repo(docs_repo_full_name)
        content_file = docs_repo.get_contents(doc_path)
        return content_file.decoded_content.decode("utf-8")
    except Exception as e:
        logger.error(f"Could not fetch doc content for {doc_path}: {e}")
        return None

def analyze_and_update_document(client, deployment, code_diff, doc_content, doc_path, file_status):
    """
    SINGLE CALL LLM: 
    1. Detects specific functions/methods/configs changed.
    2. Generates proposed changes summary.
    3. Generates full updated file content.
    """
    
    system_prompt = """
    You are an expert technical writer and code analyst.
    Your task is to compare a 'Code Diff' against 'Current Documentation' and determine necessary updates.
    
    Scope of Analysis:
    - Detect changes in functions, methods, classes, and interfaces.
    - Detect changes in Protocol Buffers (.proto), API Headers, and Configuration files (.yaml, .json, .xml).
    - Track Added, Removed, Renamed, or Moved files.
    
    Instructions:
    1. Analyze the 'Code Diff' and the provided 'File Status'.
    2. Identify specific affected functions, methods, or configuration keys.
    3. Compare with the 'Current Documentation'.
    4. Generate a summary of proposed changes.
    5. If 'needs_update' is true, rewrite the ENTIRE documentation file content.
    
    Return strictly in this JSON format:
    {
        "file_path": "string (The documentation file path)",
        "status": "string (The status of the code change: Added/Modified/Removed)",
        "needs_update": boolean,
        "reasoning": "string (Explain why update is needed)",
        "affected_functions_methods": ["string", "string"] (List of specific code elements changed),
        "proposed_ascii_changes": "string (Summary of changes in AsciiDoc format for the PR description)",
        "updated_file_content": "string (The complete new file content if needs_update is true, otherwise empty)"
    }
    """

    # Include file status in the user prompt for context
    user_prompt = f"""
    Code Status: {file_status}
    Documentation File: {doc_path}
    
    Code Diff:
    {code_diff}
    
    Current Documentation Content:
    {doc_content}
    
    Please provide the JSON analysis and updated content.
    """
    
    # Safety truncation
    max_input_length = 60000
    if len(user_prompt) > max_input_length:
        logger.warning(f"Input for {doc_path} is too long, truncating diff.")
        user_prompt = user_prompt[:max_input_length] + "\n...[Truncated]..."

    try:
        response = client.chat.completions.create(
            model=deployment,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            response_format={"type": "json_object"},
            temperature=0.2
        )
        
        return json.loads(response.choices[0].message.content)
    except Exception as e:
        logger.error(f"LLM Call failed for {doc_path}: {e}")
        return {
            "needs_update": False, 
            "reasoning": "LLM Error", 
            "affected_functions_methods": [],
            "proposed_ascii_changes": "",
            "updated_file_content": ""
        }

def create_docs_pr(g_docs, docs_repo_full_name, branch_name, updated_files, pr_title, summary_log):
    """Commits changes to the Docs repo and raises a Pull Request."""
    docs_repo = g_docs.get_repo(docs_repo_full_name)
    base_branch = docs_repo.get_branch("main")
    
    # 1. Create Branch
    try:
        docs_repo.create_git_ref(ref=f"refs/heads/{branch_name}", sha=base_branch.commit.sha)
        logger.info(f"Created branch {branch_name} in docs repo")
    except GithubException as e:
        if e.status == 422:
            logger.info("Branch already exists, proceeding.")
        else:
            raise

    # 2. Commit Files
    commit_message = f"Update docs based on source PR: {pr_title}"
    
    for path, new_content in updated_files.items():
        try:
            # Check if file exists to update
            content_file = docs_repo.get_contents(path, ref=branch_name)
            docs_repo.update_file(
                path=path, message=commit_message, content=new_content, 
                sha=content_file.sha, branch=branch_name
            )
        except GithubException:
            # Create new file
            docs_repo.create_file(
                path=path, message=commit_message, content=new_content, branch=branch_name
            )
        logger.info(f"Committed changes to {path}")

    # 3. Create Pull Request
    pr_body = "This PR was automatically generated by the AI Doc Bot.\n\n**Detailed Analysis:**\n"
    for item in summary_log:
        # Detailed body with proposed changes
        pr_body += f"---\n"
        pr_body += f"**File:** `{item['file']}`\n"
        pr_body += f"**Status:** {item['status']}\n"
        pr_body += f"**Affected Elements:** {', '.join(item['affected'])}\n"
        pr_body += f"**Reasoning:** {item['reasoning']}\n"
        pr_body += f"**Proposed Changes:**\n{item['changes']}\n\n"
        
    try:
        existing = docs_repo.get_pulls(state="open", head=branch_name.split('/')[-1])
        if list(existing):
            logger.info("PR already exists.")
            return

        docs_repo.create_pull(
            title=f"[Auto-Generated] Doc Updates for: {pr_title}",
            body=pr_body,
            head=branch_name,
            base="main"
        )
        logger.info("Pull Request created successfully.")
    except Exception as e:
        logger.error(f"Failed to create PR: {e}")

def main():
    # --- 0. Initialization ---
    g_source, g_docs, openai_client, deployment_name, docs_repo_owner, docs_repo_name = initialize_clients()
    docs_repo_full_name = f"{docs_repo_owner}/{docs_repo_name}"
    
    source_repo_full_name = os.getenv("GITHUB_REPOSITORY")
    pr_number = int(os.getenv("PR_NUMBER"))
    
    # --- 1. Fetch PR Diff (With File Status) ---
    file_details, diff_text, pr_title = get_pr_diff(g_source, source_repo_full_name, pr_number)
    
    updated_files = {}
    pr_summary = []
    processed_doc_paths = set()
    
    # --- 2. Map and Process Files ---
    for file_info in file_details:
        code_file = file_info['filename']
        file_status = file_info['status']
        
        # Identify candidate doc files
        candidate_docs = search_candidate_docs(g_docs, docs_repo_full_name, code_file, file_status)
        
        for doc_path in candidate_docs:
            if doc_path in processed_doc_paths:
                continue
            processed_doc_paths.add(doc_path)
            
            logger.info(f"Processing: {doc_path} (Code Status: {file_status})")
            
            # Fetch content. If doc doesn't exist (404), send empty string to LLM (it might need to create it)
            doc_content = fetch_doc_content(g_docs, docs_repo_full_name, doc_path)
            if doc_content is None:
                doc_content = "" # Treat as new file
            
            # --- 3. ENHANCED SINGLE CALL LLM ---
            result = analyze_and_update_document(
                openai_client, 
                deployment_name, 
                diff_text, 
                doc_content, 
                doc_path, 
                file_status
            )
            
            if result.get("needs_update") and result.get("updated_file_content"):
                logger.info(f"Updates generated for {doc_path}.")
                
                updated_files[doc_path] = result["updated_file_content"]
                pr_summary.append({
                    "file": doc_path,
                    "status": result.get("status", "Unknown"),
                    "affected": result.get("affected_functions_methods", []),
                    "reasoning": result.get("reasoning", ""),
                    "changes": result.get("proposed_ascii_changes", "")
                })
            else:
                logger.info(f"No update needed for {doc_path}.")

    # --- 4. Commit and Raise PR ---
    if updated_files:
        branch_name = f"ai-doc-update-pr-{pr_number}"
        create_docs_pr(g_docs, docs_repo_full_name, branch_name, updated_files, pr_title, pr_summary)
    else:
        logger.info("No documentation gaps found. No PR raised.")

if __name__ == "__main__":
    main()
