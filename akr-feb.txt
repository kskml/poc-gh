import os
import json
import base64
import requests
from openai import OpenAI

# --- Configuration & Clients ---
GITHUB_TOKEN = os.getenv("GITHUB_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

HEADERS = {
    "Authorization": f"Bearer {GITHUB_TOKEN}",
    "Accept": "application/vnd.github+json",
    "X-GitHub-Api-Version": "2022-11-28"
}

openai_client = OpenAI(api_key=OPENAI_API_KEY)

# --- Helper: Generic GitHub REST Calls ---

def github_get(url):
    response = requests.get(url, headers=HEADERS)
    if response.status_code == 404:
        return None
    response.raise_for_status()
    return response.json()

def github_put(url, data):
    response = requests.put(url, headers=HEADERS, json=data)
    response.raise_for_status()
    return response.json()

def github_post(url, data):
    response = requests.post(url, headers=HEADERS, json=data)
    response.raise_for_status()
    return response.json()

# --- Step 1: Data Ingestion ---

def get_pr_diff_data(code_repo_name, pr_number):
    """Fetches PR metadata and diff from the CODE repo."""
    url = f"https://api.github.com/repos/{code_repo_name}/pulls/{pr_number}"
    pr_data = github_get(url)
    
    diff_response = requests.get(pr_data["diff_url"])
    diff_response.raise_for_status()
    
    return {
        "diff": diff_response.text,
        "code_repo_head_branch": pr_data["head"]["ref"],
        "pr_title": pr_data["title"]
    }

def get_default_branch(doc_repo_name):
    """Gets the default branch of the DOC repo."""
    url = f"https://api.github.com/repos/{doc_repo_name}"
    repo_data = github_get(url)
    return repo_data["default_branch"]

def get_all_adoc_files(doc_repo_name, branch_ref):
    """Fetches all .adoc files from the DOC repo."""
    print(f"Fetching docs from repo: {doc_repo_name} on branch: {branch_ref}")
    tree_url = f"https://api.github.com/repos/{doc_repo_name}/git/trees/{branch_ref}?recursive=1"
    tree_data = github_get(tree_url)
    
    docs_map = {}
    if not tree_data: return docs_map

    for item in tree_data.get("tree", []):
        if item["type"] == "blob" and item["path"].endswith(".adoc"):
            content_url = f"https://api.github.com/repos/{doc_repo_name}/contents/{item['path']}?ref={branch_ref}"
            try:
                file_data = github_get(content_url)
                if file_data:
                    decoded_content = base64.b64decode(file_data["content"]).decode('utf-8')
                    docs_map[item["path"]] = decoded_content
            except Exception as e:
                print(f"Warning: Could not read {item['path']}: {e}")
                
    return docs_map

# --- Step 2: LLM Analysis ---

def chunk_dict(data, chunk_size=3):
    items = list(data.items())
    for i in range(0, len(items), chunk_size):
        yield dict(items[i:i + chunk_size])

def analyze_diff_in_batches(code_diff, docs_map, batch_size=3):
    """Compares Code Diff with Docs to find gaps."""
    all_proposed_changes = []
    batches = list(chunk_dict(docs_map, batch_size))
    
    print(f"Analyzing {len(docs_map)} doc files in {len(batches)} batches...")

    for i, batch in enumerate(batches):
        # Just sending filenames and a snippet might be better for context window, 
        # but sending full content ensures accuracy.
        batch_context = "\n\n".join([f"File: {path}\nContent:\n{content}" for path, content in batch.items()])

        prompt = f"""
        You are a Technical Documentation Expert.
        Analyze the 'Code Diff' from the code repository against the 'Documentation Files' from the documentation repository.
        
        Code Diff:
        {code_diff}

        Documentation Files:
        {batch_context}

        Task:
        Identify if the Code Diff requires updates to these documentation files.
        Return a JSON object with a key "updates" containing a list of objects.
        Each object must have:
        1. "filename": The exact file path from the input.
        2. "proposed_changes": A precise description of what needs to be updated.
        
        If no updates needed, return {{"updates": []}}.
        """

        try:
            response = openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": prompt}],
                response_format={"type": "json_object"}
            )
            
            result = json.loads(response.choices[0].message.content)
            if "updates" in result:
                valid_updates = [u for u in result["updates"] if u.get("filename") and u.get("proposed_changes")]
                all_proposed_changes.extend(valid_updates)
                
        except Exception as e:
            print(f"Error in batch {i+1}: {e}")

    return all_proposed_changes

# --- Step 3: Refactoring ---

def clean_adoc_content(content):
    """Removes markdown artifacts."""
    content = content.strip()
    if content.startswith("```asciidoc"): content = content[len("```asciidoc"):]
    if content.startswith("```"): content = content[len("```"):]
    if content.endswith("```"): content = content[:-len("```")]
    return content.strip()

def refactor_identified_file(original_content, proposed_changes, code_diff):
    """
    Instructs LLM to perform a surgical update.
    """
    prompt = f"""
    You are an AsciiDoc expert. Your task is to update an existing document based on specific instructions derived from a code change.
    
    # INSTRUCTIONS
    1.  Analyze the 'Proposed Changes'.
    2.  Apply these changes to the 'Original Document'.
    3.  **CRITICAL CONSTRAINT**: You must preserve the exact structure, formatting, and content of the parts that are NOT related to the proposed changes. Do NOT rewrite the whole file. Only perform the necessary additions or modifications.
    4.  The output must be valid AsciiDoc syntax.
    5.  Do NOT use Markdown code blocks (```).
    
    # Original Document
    {original_content}
    
    # Proposed Changes
    {proposed_changes}
    
    # Code Diff (For Context)
    {code_diff}
    
    # Updated Document (Raw AsciiDoc)
    """

    try:
        response = openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1
        )
        return clean_adoc_content(response.choices[0].message.content)
    except Exception as e:
        print(f"LLM Refactoring error: {e}")
        return None

def refactor_all_files(proposed_changes, doc_repo_name, doc_branch, code_diff):
    """
    1. Iterates identified changes.
    2. Fetches original content from Doc Repo.
    3. Calls LLM.
    4. Stores result in dictionary.
    """
    refactored_files_dict = {}
    
    print(f"\n--- Phase: Refactoring {len(proposed_changes)} Files in {doc_repo_name} ---")

    for change in proposed_changes:
        filename = change['filename']
        instruction = change['proposed_changes']
        
        print(f"Refactoring: {filename}")
        
        try:
            # 1. Fetch original content from DOC REPO
            url = f"https://api.github.com/repos/{doc_repo_name}/contents/{filename}?ref={doc_branch}"
            file_data = github_get(url)
            if not file_data:
                print(f"File {filename} not found in doc repo, skipping.")
                continue
                
            original_content = base64.b64decode(file_data["content"]).decode('utf-8')
            
            # 2. Send to LLM
            new_content = refactor_identified_file(original_content, instruction, code_diff)
            
            # 3. Store in Dict
            if new_content:
                if new_content != original_content:
                    refactored_files_dict[filename] = new_content
                else:
                    print(f"Skipping {filename}: Content unchanged by LLM.")
                    
        except Exception as e:
            print(f"Failed to process {filename}: {e}")
            
    return refactored_files_dict

# --- Step 4: GitHub PR Creation ---

def get_ref_sha(repo_name, ref):
    url = f"https://api.github.com/repos/{repo_name}/git/ref/heads/{ref}"
    data = github_get(url)
    return data["object"]["sha"]

def create_branch(repo_name, new_branch_name, source_sha):
    url = f"https://api.github.com/repos/{repo_name}/git/refs"
    data = {"ref": f"refs/heads/{new_branch_name}", "sha": source_sha}
    try:
        github_post(url, data)
        print(f"Created branch: {new_branch_name}")
    except requests.exceptions.HTTPError as e:
        if e.response.status_code == 422:
            print(f"Branch {new_branch_name} already exists. Reusing.")
        else:
            raise e

def commit_file(repo_name, file_path, new_content, target_branch):
    url = f"https://api.github.com/repos/{repo_name}/contents/{file_path}?ref={target_branch}"
    file_data = github_get(url)
    
    current_sha = None
    if file_data and "content" in file_data:
        current_sha = file_data["sha"]
    
    commit_url = f"https://api.github.com/repos/{repo_name}/contents/{file_path}"
    data = {
        "message": f"docs: update {file_path}",
        "content": base64.b64encode(new_content.encode('utf-8')).decode('utf-8'),
        "sha": current_sha,
        "branch": target_branch
    }
    
    github_put(commit_url, data)
    print(f"Committed: {file_path}")
    return True

def raise_pull_request(doc_repo_name, doc_base_branch, refactored_files_dict, code_pr_number, code_repo_name):
    """Creates PR in the Doc Repo."""
    if not refactored_files_dict:
        print("No files to commit.")
        return

    new_branch_name = f"doc-sync/pr-{code_pr_number}-auto"
    
    # 1. Create Branch in Doc Repo
    source_sha = get_ref_sha(doc_repo_name, doc_base_branch)
    create_branch(doc_repo_name, new_branch_name, source_sha)

    # 2. Commit
    for file_path, new_content in refactored_files_dict.items():
        try:
            commit_file(doc_repo_name, file_path, new_content, new_branch_name)
        except Exception as e:
            print(f"Error committing {file_path}: {e}")

    # 3. Create PR in Doc Repo
    pr_url = f"https://api.github.com/repos/{doc_repo_name}/pulls"
    pr_data = {
        "title": f"[Auto-Sync] Updates for PR #{code_pr_number} from {code_repo_name}",
        "body": f"Automated documentation updates triggered by code changes in {code_repo_name} PR #{code_pr_number}.",
        "head": new_branch_name,
        "base": doc_base_branch
    }
    
    try:
        pr_response = github_post(pr_url, pr_data)
        print(f"\nSuccess! Documentation PR created: {pr_response['html_url']}")
    except requests.exceptions.HTTPError as e:
        if e.response.status_code == 422:
            print("PR already exists or validation failed.")
        else:
            raise e

# --- Main Orchestrator ---

def main(code_repo_name, pr_number, doc_repo_name):
    print(f"--- Starting Flow ---")
    print(f"Code Repo: {code_repo_name} PR: #{pr_number}")
    print(f"Doc Repo: {doc_repo_name}")

    # Step 1: Fetch Code Diff & Docs
    print("\nStep 1: Fetching Data...")
    pr_info = get_pr_diff_data(code_repo_name, pr_number)
    
    # Determine where to read docs from (default branch of doc repo)
    doc_base_branch = get_default_branch(doc_repo_name)
    docs_map = get_all_adoc_files(doc_repo_name, doc_base_branch)
    
    if not docs_map:
        print("No AsciiDoc files found in doc repo.")
        return

    # Step 2: Analyze
    print("\nStep 2: Analyzing Gaps...")
    proposed_changes = analyze_diff_in_batches(pr_info["diff"], docs_map)
    
    if not proposed_changes:
        print("No gaps found.")
        return

    # Step 3: Refactor (Dict Collection)
    print("\nStep 3: Refactoring Files...")
    refactored_files = refactor_all_files(proposed_changes, doc_repo_name, doc_base_branch, pr_info["diff"])
    
    # Step 4: Raise PR in Doc Repo
    print("\nStep 4: Creating PR in Doc Repo...")
    raise_pull_request(doc_repo_name, doc_base_branch, refactored_files, pr_number, code_repo_name)

if __name__ == "__main__":
    # Example Usage
    CODE_REPO = "owner/code-repo"
    DOC_REPO = "owner/docs-repo"
    PR_NUM = 42
    
    if not GITHUB_TOKEN or not OPENAI_API_KEY:
        print("Set GITHUB_TOKEN and OPENAI_API_KEY env vars.")
    else:
        main(CODE_REPO, PR_NUM, DOC_REPO)
