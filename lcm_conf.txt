import os
import requests
import re
from dotenv import load_dotenv
from openai import AzureOpenAI
from markdownify import markdownify as md
from pathlib import Path

# Load environment variables
load_dotenv()

# --- CONFIGURATION ---
# Confluence
CONFLUENCE_BASE_URL = os.getenv("CONFLUENCE_BASE_URL")
CONFLUENCE_EMAIL = os.getenv("CONFLUENCE_EMAIL")
CONFLUENCE_API_TOKEN = os.getenv("CONFLUENCE_API_TOKEN")
PAGE_ID = os.getenv("PAGE_ID")

# GitHub
GITHUB_TOKEN = os.getenv("GITHUB_TOKEN")
GITHUB_REPO_OWNER = os.getenv("GITHUB_REPO_OWNER")
GITHUB_REPO_NAME = os.getenv("GITHUB_REPO_NAME")
GITHUB_BASE_TAG = os.getenv("GITHUB_BASE_TAG")
GITHUB_HEAD_TAG = os.getenv("GITHUB_HEAD_TAG")

# Local Diagrams
LOCAL_DIAGRAMS_PATH = os.getenv("LOCAL_DIAGRAMS_PATH")

# Azure
AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
AZURE_OPENAI_API_KEY = os.getenv("AZURE_OPENAI_API_KEY")
AZURE_OPENAI_DEPLOYMENT = os.getenv("AZURE_OPENAI_DEPLOYMENT")
AZURE_OPENAI_API_VERSION = os.getenv("AZURE_OPENAI_API_VERSION")
# ----------------------

def clean_confluence_html(html_content):
    """
    Replaces complex macros with clean text.
    IMPROVED: Tries multiple parameters for PlantUML name extraction to ensure consistency.
    """
    print("   Cleaning Draw.io and PlantUML macros...")
    
    # 1. Draw.io
    pattern_drawio = re.compile(
        r'<ac:structured-macro ac:name="drawio"[^>]*>.*?' + 
        r'<ac:parameter ac:name="diagramName">(.*?)</ac:parameter>' + 
        r'.*?</ac:structured-macro>', 
        re.DOTALL | re.IGNORECASE
    )

    def replace_drawio(match):
        name = match.group(1).strip()
        return f"\n\n**[Draw.io Diagram: {name}]**\n\n"

    cleaned_html = pattern_drawio.sub(replace_drawio, html_content)

    # 2. PlantUML - Try 'diagramName' first (Confluence standard)
    # Then fallback to 'title'
    pattern_plantuml_name = re.compile(
        r'<ac:structured-macro ac:name="plantUML"[^>]*>.*?' + 
        r'<ac:parameter ac:name="diagramName">(.*?)</ac:parameter>' + 
        r'.*?</ac:structured-macro>', 
        re.DOTALL | re.IGNORECASE
    )

    def replace_plantuml_name(match):
        name = match.group(1).strip()
        return f"\n\n**[PlantUML Diagram: {name}]**\n\n"

    cleaned_html = pattern_plantuml_name.sub(replace_plantuml_name, cleaned_html)
    
    # 3. PlantUML - Try 'title' (Fallback)
    pattern_plantuml_title = re.compile(
        r'<ac:structured-macro ac:name="plantUML"[^>]*>.*?' + 
        r'<ac:parameter ac:name="title">(.*?)</ac:parameter>' + 
        r'.*?</ac:structured-macro>', 
        re.DOTALL | re.IGNORECASE
    )

    def replace_plantuml_title(match):
        name = match.group(1).strip()
        return f"\n\n**[PlantUML Diagram: {name}]**\n\n"

    cleaned_html = pattern_plantuml_title.sub(replace_plantuml_title, cleaned_html)

    # 4. Fallback for PlantUML (Generic)
    pattern_plantuml_generic = re.compile(
        r'<ac:structured-macro ac:name="plantUML"[^>]*>.*?</ac:structured-macro>', 
        re.DOTALL | re.IGNORECASE
    )
    cleaned_html = pattern_plantuml_generic.sub("\n\n**[PlantUML Diagram]**\n\n", cleaned_html)

    # 5. General Cleanup
    fallback_pattern = re.compile(r'<ac:structured-macro[^>]*>.*?</ac:structured-macro>', re.DOTALL)
    cleaned_html = fallback_pattern.sub("\n\n**[Confluence Macro]**\n\n", cleaned_html)

    return cleaned_html

def get_confluence_content(base_url, email, token, page_id):
    auth = (email, token)
    url = f"{base_url}/rest/api/content/{page_id}?expand=body.storage"
    print(f"Fetching Confluence page ID: {page_id}...")
    response = requests.get(url, auth=auth)
    if response.status_code != 200:
        raise Exception(f"Confluence API Error: {response.status_code}")
    raw_html = response.json()['body']['storage']['value']
    clean_html = clean_confluence_html(raw_html)
    return md(clean_html)

def find_local_diagram(diagram_name, local_path):
    if not local_path or not os.path.exists(local_path):
        return None
    target_name_normalized = diagram_name.replace(" ", "_").replace("-", "_").lower()
    target_stem = target_name_normalized.rsplit(".", 1)[0]
    
    extensions = ['.puml', '.pu', '.plantuml']
    path_obj = Path(local_path)
    
    for ext in extensions:
        potential_file = path_obj / f"{target_name_normalized}{ext}"
        if potential_file.exists():
            return potential_file.read_text(encoding='utf-8')
        
        for file in path_obj.glob(f"*{ext}"):
            file_stem = file.stem.lower().replace(" ", "_").replace("-", "_")
            if file_stem == target_stem:
                print(f"      üóÇÔ∏è  Found matching diagram: {file.name}")
                return file.read_text(encoding='utf-8')
    return None

def find_top_header_level(markdown_text):
    lines = markdown_text.split('\n')
    min_level = 100 
    for line in lines:
        if line.strip().startswith('#'):
            stripped = line.strip().split()[0]
            level = len(stripped)
            if level < min_level:
                min_level = level
    return 1 if min_level == 100 else min_level

def chunk_confluence_hierarchical(markdown_text):
    print("Detecting top header level...")
    split_level = find_top_header_level(markdown_text)
    print(f"Splitting Confluence content (Level {split_level})...")
    
    lines = markdown_text.split('\n')
    chunks = []
    current_header = None
    current_content = []
    
    for line in lines:
        if line.strip().startswith('#'):
            stripped_line = line.strip()
            header_marker = stripped_line.split()[0] 
            header_level = len(header_marker)
            if header_level <= split_level:
                if current_content:
                    chunks.append({
                        'header': current_header if current_header else 'Preamble',
                        'content': "\n".join(current_content)
                    })
                current_header = stripped_line
                current_content = []
            else:
                current_content.append(line)
        else:
            current_content.append(line)
            
    if current_content:
        chunks.append({
            'header': current_header if current_header else 'Preamble',
            'content': "\n".join(current_content)
        })
    print(f"‚úÖ Created {len(chunks)} sections.")
    return chunks

def get_full_github_diff(owner, repo, base_tag, head_tag, token):
    headers = {
        "Authorization": f"token {token}",
        "Accept": "application/vnd.github.v3+json"
    }
    url = f"https://api.github.com/repos/{owner}/{repo}/compare/{base_tag}...{head_tag}"
    print(f"Fetching GitHub Diff: {base_tag} -> {head_tag}...")
    response = requests.get(url, headers=headers)
    if response.status_code != 200:
        raise Exception(f"GitHub API Error: {response.status_code} - {response.text}")
    diff_content = response.json().get('diff', '')
    print(f"‚úÖ Diff retrieved.")
    return diff_content

def analyze_single_section(client, deployment_name, section_header, section_content, full_diff, local_diag_path):
    """
    Invokes LLM with Text AND Diagram context.
    ROBUST REGEX: Handles newlines and spacing issues.
    """
    
    # ROBUST REGEX
    # Explanation:
    # \*?\*?\[    : Matches optional bold start and opening bracket
    # (PlantUML|Draw\.io) : Matches Type
    # .*?Diagram   : Matches text "Diagram" (allows spaces/newlines)
    # [\s\r\n]*   : Matches any amount of whitespace or newlines (crucial for multi-line placeholders)
    # :            : Matches colon
    # [\s\r\n]*   : Matches whitespace/newlines after colon
    # (.*?)       : Captures Name
    # [^\]]*?    : Matches non-bracket characters until close
    # \]\*?\*?    : Matches closing bracket and optional bold
    
    pattern = re.compile(
        r'\*?\*?\[(PlantUML|Draw\.io).*?Diagram[\s\r\n]*:[\s\r\n]*(.*?)[^\]]*?\]\*?\*', 
        re.IGNORECASE
    )
    
    matches = pattern.findall(section_content)
    
    if len(matches) == 0:
        if "Diagram" in section_content:
            print(f"      ‚ö†Ô∏è  Word 'Diagram' found but regex didn't match.")
            idx = section_content.find("Diagram")
            snippet = section_content[max(0, idx-40):min(len(section_content), idx+40)]
            # Normalize newlines for console print visibility
            clean_snippet = snippet.replace("\n", "\\n").replace("\r", "\\r")
            print(f"      Raw Snippet: ...{clean_snippet}...")
        else:
            print(f"      ‚ÑπÔ∏è  No diagrams detected.")

    diagram_contexts = []
    
    for match in matches:
        diag_name = match
        if not diag_name:
            diag_name = "Unknown"
        
        # Only load PlantUML
        if "plantuml" in section_content.lower(): # Check section text context to ensure type match
            # We can infer type from the captured group or just check local files
            # Assuming the regex capture found the name, try to find it locally
            diag_content = find_local_diagram(diag_name, local_diag_path)
            if diag_content:
                diagram_contexts.append(f"\n--- DIAGRAM CONTEXT: {diag_name} ---\n{diag_content}\n")
    
    prompt_diagrams = "\n".join(diagram_contexts) if diagram_contexts else "No local diagrams found."
    
    system_prompt = """
    You are an ASPICE SWE.2 Auditor analyzing a Documentation Section against Code Changes.
    
    **Context:**
    1. Confluence Text Content.
    2. (Optional) Local PlantUML Diagrams. These define System Logic Flows.
    
    **Instructions:**
    1. Check if Code Diff affects Text OR Diagram Logic.
    2. Return `NO_IMPACT` if aligned.
    3. If gap found, return ONLY a Markdown table row.
    
    **Row Format:**
    | ID | Severity | Confluence Section | Impact Scope | SWE.2 Observation (Functional) | Corrective Action |
    | 1 | üî¥ **NON-CONFORMANT** | <SECTION_TITLE> | UI/Logic/Data/API | [Observation] | [Action] |
    """

    user_prompt = f"""
    <SECTION_TITLE>{section_header}</SECTION_TITLE>
    
    CONFLUENCE TEXT CONTENT:
    {section_content}

    --- 
    
    LOCAL DIAGRAMS (PlantUML Logic):
    {prompt_diagrams}

    ---
    
    GITHUB CODE DIFF:
    {full_diff}
    """
    
    try:
        response = client.chat.completions.create(
            model=deployment_name,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.1
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"Error analyzing section '{section_header}': {e}")
        return "NO_IMPACT"

def main():
    try:
        client = AzureOpenAI(
            api_key=AZURE_OPENAI_API_KEY,
            api_version=AZURE_OPENAI_API_VERSION,
            azure_endpoint=AZURE_OPENAI_ENDPOINT
        )
    except Exception as e:
        print(f"‚ùå Initialization Error: {e}")
        return

    if not all([CONFLUENCE_BASE_URL, CONFLUENCE_EMAIL, CONFLUENCE_API_TOKEN, PAGE_ID, 
                GITHUB_TOKEN, GITHUB_REPO_OWNER, GITHUB_REPO_NAME, GITHUB_BASE_TAG, GITHUB_HEAD_TAG]):
        print("‚ùå Error: Missing configuration.")
        return

    try:
        doc_text = get_confluence_content(CONFLUENCE_BASE_URL, CONFLUENCE_EMAIL, CONFLUENCE_API_TOKEN, PAGE_ID)
        sections = chunk_confluence_hierarchical(doc_text)
        full_diff = get_full_github_diff(GITHUB_REPO_OWNER, GITHUB_REPO_NAME, GITHUB_BASE_TAG, GITHUB_HEAD_TAG, GITHUB_TOKEN)
        
        if not full_diff:
            print("‚ö†Ô∏è  No Diff found.")
            return

        print(f"üîÑ Starting Analysis across {len(sections)} sections...")
        accumulated_rows = []
        
        for idx, section in enumerate(sections):
            print(f"   Analyzing Section {idx+1}/{len(sections)}: {section['header']}")
            
            result = analyze_single_section(
                client, 
                AZURE_OPENAI_DEPLOYMENT, 
                section['header'], 
                section['content'], 
                full_diff,
                LOCAL_DIAGRAMS_PATH
            )
            
            if result and result != "NO_IMPACT":
                accumulated_rows.append(result)
                print(f"      ‚Üí Impact Found.")
            else:
                print(f"      ‚Üí No Impact. Skipping.")

        if not accumulated_rows:
            print("‚úÖ No gaps found.")
        else:
            with open("Ultimate_Fix_Report.md", "w", encoding="utf-8") as f:
                f.write("# ASPICE SWE.2 Analysis\n\n")
                f.write(f"**Release:** `{GITHUB_BASE_TAG}` ‚Üí `{GITHUB_HEAD_TAG}`\n\n")
                f.write("## Assessment Criteria\n\n")
                f.write("| Option | Definition |\n| :--- | :--- |\n")
                f.write("| üî¥ **NON-CONFORMANT** | Code contradicts doc or diagram. |\n")
                f.write("| üü† **GAP IDENTIFIED** | Code adds missing feature. |\n")
                f.write("| üî¥ **NON-CONFORMANT / GAP** | Complex change. |\n")
                f.write("| üü° **INCONSISTENCY** | Minor mismatch. |\n\n")
                f.write("## Analysis\n\n")
                f.write("| ID | Severity | Confluence Section | Impact Scope | SWE.2 Observation | Corrective Action |\n")
                f.write("| :--- | :--- | :--- | :--- | :--- | :--- |\n")
                for row in accumulated_rows:
                    f.write(row.replace("\n", "<br/>") + "\n")
            print(f"‚úÖ Report generated.")

    except Exception as e:
        print(f"‚ùå Error: {e}")

if __name__ == "__main__":
    main()
