import os
import requests
import re
from dotenv import load_dotenv
from openai import AzureOpenAI
from markdownify import markdownify as md
from pathlib import Path

# Load environment variables
load_dotenv()

# --- CONFIGURATION ---
# Confluence
CONFLUENCE_BASE_URL = os.getenv("CONFLUENCE_BASE_URL")
CONFLUENCE_EMAIL = os.getenv("CONFLUENCE_EMAIL")
CONFLUENCE_API_TOKEN = os.getenv("CONFLUENCE_API_TOKEN")
PAGE_ID = os.getenv("PAGE_ID")

# GitHub
GITHUB_TOKEN = os.getenv("GITHUB_TOKEN")
GITHUB_REPO_OWNER = os.getenv("GITHUB_REPO_OWNER")
GITHUB_REPO_NAME = os.getenv("GITHUB_REPO_NAME")
GITHUB_BASE_TAG = os.getenv("GITHUB_BASE_TAG")   # e.g., "v1.0.0"
GITHUB_HEAD_TAG = os.getenv("GITHUB_HEAD_TAG")   # e.g., "v1.1.0"

# Local Diagrams
LOCAL_DIAGRAMS_PATH = os.getenv("LOCAL_DIAGRAMS_PATH") # e.g., "./diagrams"

# Azure
AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
AZURE_OPENAI_API_KEY = os.getenv("AZURE_OPENAI_API_KEY")
AZURE_OPENAI_DEPLOYMENT = os.getenv("AZURE_OPENAI_DEPLOYMENT")
AZURE_OPENAI_API_VERSION = os.getenv("AZURE_OPENAI_API_VERSION")
# ----------------------

def clean_confluence_html(html_content):
    """Replaces complex macros with clean markdown placeholders."""
    print("   Cleaning Draw.io and PlantUML macros from HTML...")
    
    # Regex patterns
    pattern_drawio = re.compile(
        r'<ac:structured-macro ac:name="drawio"[^>]*>.*?' + 
        r'<ac:parameter ac:name="diagramName">(.*?)</ac:parameter>' + 
        r'.*?</ac:structured-macro>', re.DOTALL
    )

    def replace_drawio(match):
        name = match.group(1).strip()
        return f"\n\n**[Draw.io Diagram: {name}]**\n\n"

    cleaned_html = pattern_drawio.sub(replace_drawio, html_content)

    pattern_plantuml_title = re.compile(
        r'<ac:structured-macro ac:name="plantUML"[^>]*>.*?' + 
        r'<ac:parameter ac:name="title">(.*?)</ac:parameter>' + 
        r'.*?</ac:structured-macro>', re.DOTALL
    )

    def replace_plantuml_title(match):
        title = match.group(1).strip()
        return f"\n\n**[PlantUML Diagram: {title}]**\n\n"

    cleaned_html = pattern_plantuml_title.sub(replace_plantuml_title, cleaned_html)

    pattern_plantuml_generic = re.compile(
        r'<ac:structured-macro ac:name="plantUML"[^>]*>.*?</ac:structured-macro>', re.DOTALL
    )
    cleaned_html = pattern_plantuml_generic.sub("\n\n**[PlantUML Diagram]**\n\n", cleaned_html)

    # General cleanup
    fallback_pattern = re.compile(r'<ac:structured-macro[^>]*>.*?</ac:structured-macro>', re.DOTALL)
    cleaned_html = fallback_pattern.sub("\n\n**[Confluence Macro]**\n\n", cleaned_html)

    return cleaned_html

def get_confluence_content(base_url, email, token, page_id):
    """Fetches documentation, cleans HTML artifacts, and converts to Markdown."""
    auth = (email, token)
    url = f"{base_url}/rest/api/content/{page_id}?expand=body.storage"
    print(f"Fetching Confluence page ID: {page_id}...")
    response = requests.get(url, auth=auth)
    if response.status_code != 200:
        raise Exception(f"Confluence API Error: {response.status_code}")
    
    raw_html = response.json()['body']['storage']['value']
    clean_html = clean_confluence_html(raw_html)
    return md(clean_html)

def find_local_diagram(diagram_name, local_path):
    """
    Searches local_path for a .puml/.pu file matching diagram_name.
    Performs fuzzy matching (spaces <-> underscores, case insensitive).
    """
    if not local_path or not os.path.exists(local_path):
        return None
        
    # Normalize target name: "Order Flow" -> "order_flow"
    target_name_normalized = diagram_name.replace(" ", "_").replace("-", "_").lower()
    target_stem = target_name_normalized.rsplit(".", 1)[0] # remove extension if passed
    
    # Common extensions
    extensions = ['.puml', '.pu', '.plantuml']
    
    # Iterate files
    path_obj = Path(local_path)
    for ext in extensions:
        # Try exact match first
        potential_file = path_obj / f"{target_name_normalized}{ext}"
        if potential_file.exists():
            return potential_file.read_text(encoding='utf-8')
        
        # Try stem match (in case file is "Order_Flow.puml" and name is "Order Flow")
        for file in path_obj.glob(f"*{ext}"):
            file_stem = file.stem.lower().replace(" ", "_").replace("-", "_")
            if file_stem == target_stem:
                print(f"      üóÇÔ∏è  Found matching diagram: {file.name}")
                return file.read_text(encoding='utf-8')
                
    return None

def find_top_header_level(markdown_text):
    lines = markdown_text.split('\n')
    min_level = 100 
    for line in lines:
        if line.strip().startswith('#'):
            stripped = line.strip().split()[0]
            level = len(stripped)
            if level < min_level:
                min_level = level
    return 1 if min_level == 100 else min_level

def chunk_confluence_hierarchical(markdown_text):
    print("Detecting top header level...")
    split_level = find_top_header_level(markdown_text)
    print(f"Splitting Confluence content (Auto-detected Level {split_level})...")
    
    lines = markdown_text.split('\n')
    chunks = []
    current_header = None
    current_content = []
    
    for line in lines:
        if line.strip().startswith('#'):
            stripped_line = line.strip()
            header_marker = stripped_line.split()[0] 
            header_level = len(header_marker)
            
            if header_level <= split_level:
                if current_content:
                    chunks.append({
                        'header': current_header if current_header else 'Preamble',
                        'content': "\n".join(current_content)
                    })
                current_header = stripped_line
                current_content = []
            else:
                current_content.append(line)
        else:
            current_content.append(line)
            
    if current_content:
        chunks.append({
            'header': current_header if current_header else 'Preamble',
            'content': "\n".join(current_content)
        })
        
    print(f"‚úÖ Created {len(chunks)} sections.")
    return chunks

def get_full_github_diff(owner, repo, base_tag, head_tag, token):
    headers = {
        "Authorization": f"token {token}",
        "Accept": "application/vnd.github.v3+json"
    }
    url = f"https://api.github.com/repos/{owner}/{repo}/compare/{base_tag}...{head_tag}"
    print(f"Fetching GitHub Diff: {base_tag} -> {head_tag}...")
    
    response = requests.get(url, headers=headers)
    if response.status_code != 200:
        raise Exception(f"GitHub API Error: {response.status_code} - {response.text}")
    
    diff_content = response.json().get('diff', '')
    print(f"‚úÖ Diff retrieved (Length: {len(diff_content)} chars).")
    return diff_content

def analyze_single_section(client, deployment_name, section_header, section_content, full_diff, local_diag_path):
    """
    Invokes LLM with Text AND Diagram context.
    """
    
    # 1. Detect Diagram Placeholders in content
    # We look for **[PlantUML Diagram: Name]** or **[Draw.io Diagram: Name]**
    diagram_contexts = []
    # Regex to find diagram names
    pattern = re.compile(r'\*\*\[(PlantUML|Draw.io) Diagram: (.*?)\]\*\*')
    
    matches = pattern.findall(section_content)
    
    for match in matches:
        diag_type, diag_name = match
        # Only load PlantUML locally (Draw.io is often binary/XML complex)
        if diag_type == "PlantUML":
            diag_content = find_local_diagram(diag_name, local_diag_path)
            if diag_content:
                diagram_contexts.append(f"\n--- DIAGRAM CONTEXT: {diag_name} ---\n{diag_content}\n")
    
    # 2. Build Prompt
    prompt_diagrams = "\n".join(diagram_contexts) if diagram_contexts else "No local diagrams found for this section."
    
    system_prompt = """
    You are an ASPICE SWE.2 Auditor.
    You are analyzing ONE specific section of documentation against a Software Release Code Diff.
    
    **Context Provided:**
    1. Confluence Text Content.
    2. (Optional) Local PlantUML Diagrams. These diagrams represent System Logic, State Flows, or Architectural Contracts. Treat the text INSIDE these diagrams as equivalent to written specifications.
    
    **Instructions:**
    1. Read the "Confluence Text Content".
    2. Read "Local Diagrams" (if present).
    3. Read the "GitHub Code Diff".
    4. Determine if the changes in the Diff affect this Section OR the Logic defined in the Diagrams.
    
    **Output Rules:**
    - If aligned and no updates needed, return exactly: `NO_IMPACT`.
    - If there IS a gap, return ONLY a Markdown table row.
    
    **Severity Definitions:**
    - üî¥ **NON-CONFORMANT:** Code contradicts doc or diagram logic.
    - üü† **GAP IDENTIFIED:** Code adds new feature missing from docs/diagrams.
    - üî¥ **NON-CONFORMANT / GAP:** Complex change violating spec.
    - üü° **INCONSISTENCY:** Minor mismatch.
    
    **CRITICAL:**
    - The "Confluence Section" column MUST use the value from <SECTION_TITLE> tags.
    - If a gap is found in the diagram logic, mention it in the Observation (e.g., "Diagram shows state X, but code implements state Y").
    
    **Row Format:**
    | ID | Severity | Confluence Section | Impact Scope | SWE.2 Observation (Functional) | Corrective Action |
    | 1 | üî¥ **NON-CONFORMANT** | <SECTION_TITLE> | UI/Logic/Data/API | [Observation] | [Action] |
    """

    user_prompt = f"""
    <SECTION_TITLE>{section_header}</SECTION_TITLE>
    
    CONFLUENCE TEXT CONTENT:
    {section_content}

    --- 
    
    LOCAL DIAGRAMS (PlantUML Logic):
    {prompt_diagrams}

    ---
    
    GITHUB CODE DIFF (Release Changes):
    {full_diff}
    """
    
    try:
        response = client.chat.completions.create(
            model=deployment_name,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.1
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"Error analyzing section '{section_header}': {e}")
        return "NO_IMPACT"

def main():
    # 1. Initialize Clients
    try:
        client = AzureOpenAI(
            api_key=AZURE_OPENAI_API_KEY,
            api_version=AZURE_OPENAI_API_VERSION,
            azure_endpoint=AZURE_OPENAI_ENDPOINT
        )
    except Exception as e:
        print(f"‚ùå Initialization Error: {e}")
        return

    if not all([CONFLUENCE_BASE_URL, CONFLUENCE_EMAIL, CONFLUENCE_API_TOKEN, PAGE_ID, 
                GITHUB_TOKEN, GITHUB_REPO_OWNER, GITHUB_REPO_NAME, GITHUB_BASE_TAG, GITHUB_HEAD_TAG]):
        print("‚ùå Error: Missing configuration.")
        return

    try:
        # 2. Fetch Docs
        doc_text = get_confluence_content(CONFLUENCE_BASE_URL, CONFLUENCE_EMAIL, CONFLUENCE_API_TOKEN, PAGE_ID)
        
        # 3. Chunk Docs
        sections = chunk_confluence_hierarchical(doc_text)
        
        # 4. Fetch GitHub Diff
        full_diff = get_full_github_diff(GITHUB_REPO_OWNER, GITHUB_REPO_NAME, GITHUB_BASE_TAG, GITHUB_HEAD_TAG, GITHUB_TOKEN)
        
        if not full_diff:
            print("‚ö†Ô∏è  No Diff found to analyze.")
            return

        # 5. Iterative Analysis
        print(f"üîÑ Starting Analysis across {len(sections)} major sections...")
        accumulated_rows = []
        
        for idx, section in enumerate(sections):
            print(f"   Analyzing Section {idx+1}/{len(sections)}: {section['header']}")
            
            result = analyze_single_section(
                client, 
                AZURE_OPENAI_DEPLOYMENT, 
                section['header'], 
                section['content'], 
                full_diff,
                LOCAL_DIAGRAMS_PATH
            )
            
            # 6. Filter Logic
            if result and result != "NO_IMPACT":
                accumulated_rows.append(result)
                print(f"      ‚Üí Impact Found.")
            else:
                print(f"      ‚Üí No Impact. Skipping.")

        # 7. Generate Final Markdown Report
        if not accumulated_rows:
            print("‚úÖ No gaps found across all sections. Report not generated.")
        else:
            with open("Diagram_Aware_Report.md", "w", encoding="utf-8") as f:
                f.write("# ASPICE SWE.2 Sectional Impact Analysis (Including Diagrams)\n\n")
                f.write(f"**Release Comparison:** `{GITHUB_BASE_TAG}` ‚Üí `{GITHUB_HEAD_TAG}`\n\n")
                f.write("---\n\n")
                f.write("## Assessment Criteria & Definitions\n\n")
                f.write("| Option | Definition |\n")
                f.write("| :--- | :--- |\n")
                f.write("| üî¥ **NON-CONFORMANT** | Code behavior contradicts the existing Functional Specification or Diagram Logic. |\n")
                f.write("| üü† **GAP IDENTIFIED** | Code implements new functionality that is missing from the Specification or Diagram. |\n")
                f.write("| üî¥ **NON-CONFORMANT / GAP** | A complex change that **both** violates the existing specification AND introduces new undocumented behavior. |\n")
                f.write("| üü° **INCONSISTENCY** | Minor discrepancies in parameter definitions or descriptions. |\n")
                f.write("\n---\n\n")
                f.write("## Detailed Functional Analysis\n\n")
                
                f.write("| ID | Severity | Confluence Section | Impact Scope | SWE.2 Observation (Functional) | Corrective Action |\n")
                f.write("| :--- | :--- | :--- | :--- | :--- | :--- |\n")
                
                for row in accumulated_rows:
                    clean_row = row.replace("\n", "<br/>")
                    f.write(clean_row + "\n")
            
            print(f"‚úÖ Report generated: Diagram_Aware_Report.md")

    except Exception as e:
        print(f"‚ùå Execution Error: {e}")

if __name__ == "__main__":
    main()
